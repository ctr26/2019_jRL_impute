{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics, preprocessing\n",
        "from sklearn import pipeline, model_selection\n",
        "\n",
        "# from keras import backend as K\n",
        "from scipy.stats import pearsonr\n",
        "# from sklearn import svm, linear_model\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import microscPSF.microscPSF as msPSF\n",
        "# import PIL\n",
        "import scipy\n",
        "\n",
        "# from scipy import matrix\n",
        "# from scipy.sparse import coo_matrix\n",
        "# import time\n",
        "# from scipy import linalg\n",
        "# from skimage import color, data, restoration\n",
        "# from skimage.transform import rescale, resize, downscale_local_mean\n",
        "# from scipy.signal import convolve2d as conv2\n",
        "# import matlab.engine\n",
        "# import pandas as pd\n",
        "\n",
        "# import keras\n",
        "from keras import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.layers import Dense, Dropout, Activation, Convolution1D, Flatten, Conv1D, UpSampling1D, InputLayer, UpSampling2D, Conv2D, Reshape, Input, LeakyReLU, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# from sklearn.preprocessing import Imputer\n",
        "# from sklearn.experimental import enable_iterative_imputer\n",
        "# from sklearn.impute import IterativeImputer\n",
        "# from sklearn.experimental import enable_iterative_imputer\n",
        "# from scipy import signal\n",
        "# from sklearn.impute import SimpleImputer\n",
        "\n",
        "# import os\n",
        "\n",
        "# x,y,image_x,image_y\n",
        "\n",
        "print(\"Get data\")\n",
        "\n",
        "psf_window_volume_nuked = np.load('data/psf_window_volume_nuked.npy')\n",
        "psf_window_volume = np.load('data/psf_window_volume.npy')\n",
        "\n",
        "measurement_matrix_4d_nuked = np.load('data/measurement_matrix_4d_nuked.npy')\n",
        "measurement_matrix_4d = np.load('data/measurement_matrix_4d.npy')\n",
        "\n",
        "# np.sum(np.isfinite(measurement_matrix_3d_nuked[:,0,0]))\n",
        "\n",
        "measurement_matrix_3d_nuked = measurement_matrix_4d_nuked.reshape([-1,128, 128])\n",
        "measurement_matrix_3d = np.reshape(measurement_matrix_4d, [-1, 128, 128])\n",
        "\n",
        "measurement_matrix_nuked = measurement_matrix_4d_nuked.reshape(-1,128*128)\n",
        "measurement_matrix = measurement_matrix_4d.reshape([-1,128*128])\n",
        "\n",
        "# measurement_matrix_a = np.reshape(measurement_matrix_4d,[128,128,128,128])\n",
        "\n",
        "# plt.imshow(measurement_matrix_a[64,64,:,:])\n",
        "# plt.imshow(np.reshape(measurement_matrix[0], (128, 128)))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Regress full PSF model\")\n",
        "\n",
        "\n",
        "def nd_scaler(x): return StandardScaler().fit_transform(\n",
        "    x.reshape(x.shape[0],-1)).reshape(x.shape)\n",
        "\n",
        "coords = np.array(np.unravel_index(\n",
        "                        np.arange(0, measurement_matrix_nuked[0].size),\n",
        "                        measurement_matrix_4d_nuked.shape[0:2])).T;coords.shape\n",
        "\n",
        "y_values = measurement_matrix_nuked\n",
        "y_ground_truth = measurement_matrix\n",
        "\n",
        "\n",
        "coords_nuked = np.array(np.unravel_index(\n",
        "                        np.arange(0, y_values[0].size),\n",
        "                        y_values.shape[0:2])).T;coords_nuked.shape\n",
        "x_indices = coords_nuked\n",
        "\n",
        "# plt.imshow(y_values)\n",
        "nuked_finite_rows = np.any(np.isfinite(y_values), axis=1)\n",
        "\n",
        "x_indices_clean = x_indices[nuked_finite_rows];x_indices_clean.shape\n",
        "y_values_clean = y_values[nuked_finite_rows];y_values_clean.shape\n",
        "\n",
        "y_values_2d_clean_128 = measurement_matrix_3d_nuked[nuked_finite_rows];y_values_2d_clean_128.shape\n",
        "y_values_2d_clean_128_scaled = nd_scaler(measurement_matrix_3d_nuked[nuked_finite_rows]);y_values_2d_clean_128.shape\n",
        "\n",
        "y_ground_truth_2d_128 = measurement_matrix_3d\n",
        "\n",
        "y_values_2d_clean = psf_window_volume_nuked[nuked_finite_rows];y_values_2d_clean.shape\n",
        "y_values_2d_clean_scaled = nd_scaler(y_values_2d_clean);y_values_2d_clean_scaled.shape\n",
        "\n",
        "y_ground_truth_2d = psf_window_volume;y_ground_truth_2d.shape\n",
        "\n",
        "y_values_2d_clean = psf_window_volume_nuked[nuked_finite_rows];y_values_2d_clean.shape\n",
        "y_ground_truth_2d_scaled = nd_scaler(y_ground_truth_2d);y_ground_truth_2d_scaled.shape\n",
        "\n",
        "x_indices_clean_scaled = preprocessing.scale(x_indices_clean);x_indices_clean_scaled.shape\n",
        "x_indices_scaled = preprocessing.scale(x_indices);x_indices_scaled.shape\n",
        "\n",
        "# y_values_2d_clean_scaled = preprocessing.scale(y_values_2d_clean)\n",
        "y_values_clean_scaled = preprocessing.scale(y_values_clean)\n",
        "y_ground_truth_scaled = preprocessing.scale(y_ground_truth)\n",
        "\n",
        "x_test = x_indices_scaled\n",
        "\n",
        "\n",
        "# y_ground_truth_2d_clean = measurement_matrix_3d;y_ground_truth_2d_clean.shape\n",
        "# y_ground_truth.shape\n",
        "plt.imshow(np.reshape(y_ground_truth[127*0],(128,128)))\n",
        "\n",
        "# plt.imshow(y_ground_truth_2d[127*127])\n",
        "plt.imshow(y_ground_truth_2d[0])\n",
        "# y_ground_truth_2d\n",
        "plt.imshow(measurement_matrix_4d[127,127,:,:])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NN models\")\n",
        "\n",
        "def keras_model_cov():\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=x_indices_clean_scaled.shape))\n",
        "    model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
        "    model.add(UpSampling1D(size=2))\n",
        "    model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
        "    # model.add(UpSampling1D(size=2))\n",
        "    # model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
        "    # model.add(UpSampling1D(size=2))\n",
        "    # model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
        "    model.add(UpSampling1D(size=2))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    # model.add(Dropout(0.5))\n",
        "    # model.add(Dense(256, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def keras_model_fc():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "classifiers = [\n",
        "    # svm.SVR(),\n",
        "    # neural_network.MLPRegressor(hidden_layer_sizes=(64,64),\n",
        "    #                             verbose=True),\n",
        "    # neighbors.KNeighborsRegressor(),\n",
        "    KerasRegressor(build_fn=keras_model_cov, epochs=100,\n",
        "                   nb_epoch=100, batch_size=64, verbose=1),\n",
        "    KerasRegressor(build_fn=keras_model_fc, epochs=100,\n",
        "                   nb_epoch=100, batch_size=64, verbose=1)\n",
        "    # svm.SVR(),\n",
        "    # gaussian_process.GaussianProcessRegressor(),\n",
        "    # linear_model.SGDRegressor(),\n",
        "    # linear_model.BayesianRidge(),\n",
        "    # linear_model.LassoLars(),\n",
        "    # linear_model.ARDRegression(),\n",
        "    # linear_model.PassiveAggressiveRegressor(),\n",
        "    # linear_model.TheilSenRegressor(),\n",
        "    # linear_model.LinearRegression()\n",
        "]\n",
        "\n",
        "# Need to invert scaling\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "# DO IT ALL IN 2D\n",
        "\n",
        "\n",
        "# (*x_indices_scaled.shape,1)\n",
        "# histor = the_model.fit(x_indices_clean_scaled, y_values_clean_2d_scaled)\n",
        "# x_indices_scaled.shape\n",
        "\n",
        "samples = x_indices_scaled.shape[0]\n",
        "feature_size = 3\n",
        "\n",
        "# x = np.expand_dims(x_indices_scaled, -1)\n",
        "\n",
        "BUILD_MODEL = 1\n",
        "layer_shape = 2\n",
        "output_size =128\n",
        "if(BUILD_MODEL):\n",
        "    def keras_model_cov1d():\n",
        "        model = keras.models.Sequential()\n",
        "        layer_shape = 2\n",
        "        model.add(Dense(2, input_dim=layer_shape))\n",
        "        model.add(LeakyReLU(alpha=0.05))\n",
        "        # model.add(Reshape((layer_shape, 1, 1)))\n",
        "        # model.add(Flatten())\n",
        "        for i in np.arange(0, 12):\n",
        "            model.add(Reshape((layer_shape, 1, 1)))\n",
        "            model.add(UpSampling2D(size=(2, 1)))\n",
        "            model.add(Reshape((layer_shape * 2, 1)))\n",
        "            model.add(Conv1D(filters=1, kernel_size=2, activation='relu'))\n",
        "            model.add(Flatten())\n",
        "            # model.add(Dropout(0.5))\n",
        "\n",
        "            layer_shape = layer_shape * 2 - 1\n",
        "        model.add(Dense(128))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(128 * 128))\n",
        "        model.add(LeakyReLU(alpha=0.05))\n",
        "        model.add(Dropout(0.2))\n",
        "        # model.add(Flatten())\n",
        "        # model.add(Dropout(0.5))\n",
        "        # model.add(Dense(100, activation='relu'))\n",
        "        model.compile(loss='mean_squared_error',\n",
        "                      optimizer='adam',\n",
        "                      metrics=[metrics.mae, metrics.accuracy])\n",
        "        # loss = keras.optimizers.Adadelta()\n",
        "        # model.compile(loss='mean_squared_error',\n",
        "        #               optimizer=loss,\n",
        "        #               metrics=['accuracy'])\n",
        "        model.compile(loss='logcosh',\n",
        "                      optimizer='sgd',\n",
        "                      metrics=['accuracy'])\n",
        "        model.build()\n",
        "        return model\n",
        "\n",
        "    def keras_model_cov2d(layer_shape=2, output_size=128):\n",
        "        iterations = np.log2(output_size) - 1\n",
        "        model = keras.models.Sequential()\n",
        "        model.add(Dense(128, input_dim=layer_shape))\n",
        "        model.add(LeakyReLU(alpha=0.05))\n",
        "        model.add(Dense(2))\n",
        "        # model.add(Conv2D(filters=2, kernel_size=2, activation='relu'))\n",
        "        model.add(Reshape((layer_shape, 1, 1)))\n",
        "        model.add(UpSampling2D(size=(1, 2)))\n",
        "        for i in np.arange(0, iterations):\n",
        "            model.add(UpSampling2D(size=(4, 4)))\n",
        "            # model.add(Conv2D(filters=2, kernel_size=2, activation='relu'))\n",
        "            model.add(Conv2D(32, 3, activation='relu',\n",
        "                             padding='same', kernel_initializer='he_normal'))\n",
        "            model.add(LeakyReLU(alpha=0.05))\n",
        "            model.add(Conv2D(32, 3, activation='relu',\n",
        "                          padding='same', kernel_initializer='he_normal'))\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "            model.add(Dropout(0.5))\n",
        "        # model.add(MaxPooling2D(pool_size=(128/9, 128/9)))\n",
        "        model.add(Conv2D(32, 3, activation='relu',\n",
        "                         padding='same', kernel_initializer='he_normal'))\n",
        "        model.add(Conv2D(2, 3, activation='relu', padding='same',\n",
        "                         kernel_initializer='he_normal'))\n",
        "        model.add(Conv2D(1, 1, activation='sigmoid'))\n",
        "        model.add(Reshape((output_size, output_size)))\n",
        "        model.summary()\n",
        "        model.compile(loss='mean_squared_error',\n",
        "                      optimizer='adam',\n",
        "                      metrics=[metrics.mae, metrics.accuracy])\n",
        "        model.build()\n",
        "        return model\n",
        "model = keras_model_cov1d()\n",
        "model = keras_model_cov2d(output_size=16)\n",
        "epochs = 10\n",
        "seed = 7\n",
        "# scikit_model = KerasClassifier(build_fn=model, epochs=epochs, batch_size=batch_size)\n",
        "# x_indices_clean_scaled.shape\n",
        "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "# results = cross_validate(scikit_model, x_indices_clean_scaled, y_values_2d_clean, cv=kfold)\n",
        "\n",
        "# model.summary()\n",
        "# plt.imshow(y_values_2d_clean_scaled[0])\n",
        "\n",
        "# model.fit(x_indices_clean, y_values_2d_clean_scaled,\n",
        "#           # validation_data=(x_test, y_ground_truth_2d_scaled),\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs)\n",
        "#\n",
        "# model.save('keras_model_cov2d_flat_2.h5')\n",
        "\n",
        "# y_predictions = model.predict(x_test)\n",
        "# score = model.evaluate(x=x_test, y=y_ground_truth_2d_scaled, verbose=1)\n",
        "\n",
        "# plt.imshow(np.sum(y_values_2d_clean, axis=0))\n",
        "# plt.imshow(np.sum(y_ground_truth_2d_scaled[nuked_finite_rows], axis=0))\n",
        "# plt.imshow(np.sum(y_predictions[nuked_finite_rows], axis=0))\n",
        "#\n",
        "#\n",
        "# plt.imshow(y_predictions[64 * 64])\n",
        "\n",
        "\n",
        "########### CARE MODEL\n",
        "\n",
        "from csbdeep.utils import axes_dict, plot_some, plot_history\n",
        "from csbdeep.utils.tf import limit_gpu_memory\n",
        "from csbdeep.io import load_training_data\n",
        "from csbdeep.models import Config, IsotropicCARE,CARE\n",
        "from csbdeep.utils import download_and_extract_zip_file, axes_dict, plot_some, plot_history\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "delta_array = np.zeros((coords.shape[0],128,128))\n",
        "\n",
        "for i in np.arange(0,coords.shape[0]):\n",
        "    delta_array[i,coords[i,0],coords[i,1]] = 1\n",
        "\n",
        "delta_array_nuked = delta_array[nuked_finite_rows]\n",
        "\n",
        "X = np.expand_dims(delta_array_nuked, -1);X.shape\n",
        "Y = np.expand_dims(y_values_2d_clean_128,-1);Y.shape\n",
        "X_val = np.expand_dims(delta_array,-1);X_val.shape\n",
        "Y_val = np.expand_dims(y_ground_truth_2d_128,-1);Y_val.shape\n",
        "\n",
        "# plt.imshow(y_ground_truth_2d_128[int((128*128)/2 + 128/2)])\n",
        "\n",
        "# im = Image.fromarray(y_values_2d_clean_128[600]).convert(\"RGB\")\n",
        "# im.show()\n",
        "# plt.imshow(y_values_2d_clean[500])\n",
        "\n",
        "\n",
        "# download_and_extract_zip_file (\n",
        "#     url       = 'http://csbdeep.bioimagecomputing.com/example_data/synthetic_disks.zip',\n",
        "#     targetdir = 'data',\n",
        "# )\n",
        "# (_,_), (_,_), axes = load_training_data('data/synthetic_disks/data.npz', validation_split=0.1, verbose=True)\n",
        "\n",
        "axes = 'SYXC'\n",
        "c = axes_dict(axes)['C'];c\n",
        "n_channel_in, n_channel_out = X.shape[c], Y.shape[c]\n",
        "\n",
        "# plt.figure(figsize=(12,5))\n",
        "plot_some(X_val[:5],Y_val[:5])\n",
        "plt.suptitle('5 example validation patches (top row: source, bottom row: target)');\n",
        "config = Config(axes, n_channel_in, n_channel_out, probabilistic=True, train_steps_per_epoch=30)\n",
        "print(config)\n",
        "vars(config)\n",
        "\n",
        "\n",
        "# axes ='XY'\n",
        "# config = Config(axes, 1, 1, train_steps_per_epoch=30)\n",
        "model = CARE(config, 'my_model', basedir='models')\n",
        "history = model.train(X,Y, validation_data=(X_val,Y_val))\n",
        "\n",
        "# history = model.train(X,Y, validation_data=(X_val,Y_val))\n",
        "\n",
        "\n",
        "\n",
        "    #\n",
        "# coords = np.unravel_index(i, astro.shape)\n",
        "#\n",
        "# # plt.imshow()\n",
        "# y_predict = model.predict(x)\n",
        "# for i in np.arange(N_v):\n",
        "#     y_predict_current = y_predict[i, :].reshape((10, 10))\n",
        "#     plt.imsave(\n",
        "#         f'./output/predict_psf/{str(i).zfill(6)}.png', y_predict_current)\n",
        "# # plt.imsave(,)\n",
        "#\n",
        "# # np.nansum(np.sqrt(y_predict**2-y**2))\n",
        "#\n",
        "# # plt.imshow(a.reshape((10,10)))\n",
        "#\n",
        "# plt.imshow(measurement_matrix_3d[:, :, ].reshape((10, 10)))\n",
        "# samples = measurement_matrix_3d_nuked.shape[2]\n",
        "#\n",
        "# model = keras_model_fc()\n",
        "# # for classifier in classifiers:\n",
        "# # print(classifier)\n",
        "# classifier = classifiers[1]\n",
        "#\n",
        "# name = classifier.__module__\n",
        "# print(f'{name}')\n",
        "# classifier.fit(x_indices_clean_scaled, y_values_clean_scaled)\n",
        "# y_values_predict_scaled = classifier.predict(x_indices_scaled)\n",
        "#\n",
        "# score = classifier.score(x_indices_scaled, y_ground_truth_scaled)\n",
        "# mse = metrics.mean_squared_error(\n",
        "#     y_ground_truth_scaled, y_values_predict_scaled)\n",
        "# r2 = metrics.r2_score(y_ground_truth_scaled, y_values_predict_scaled)\n",
        "# # classifier.score()\n",
        "# correlation, p_value = pearsonr(\n",
        "#     y_ground_truth_scaled.flatten(), y_values_predict_scaled.flatten())\n",
        "# print(\n",
        "#     f'Correlation: {correlation:.5f} | MSE:{mse:.5f} |  R2:{r2:.5f}  | Score:{score:.5f}')\n",
        "# # plt.scatter(y_ground_truth_scaled,y_values_predict_scaled)\n",
        "# # from sklearn.neural_network import MLPClassifier\n",
        "# kfold = model_selection.KFold(n_splits=10)\n",
        "# results = model_selection.cross_val_score(classifier,\n",
        "#                                           x_indices_clean_scaled,\n",
        "#                                           y_values_clean_scaled,\n",
        "#                                           cv=kfold)\n",
        "#\n",
        "#\n",
        "# estimators = []\n",
        "# estimators.append(('standardize', preprocessing.StandardScaler()))\n",
        "# estimators.append(('model', classifiers[1]))\n",
        "# pipeline = pipeline.Pipeline(estimators)\n",
        "#\n",
        "# results = model_selection.cross_val_score(pipeline,\n",
        "#                                           X_indices_clean,\n",
        "#                                           y_values_clean,\n",
        "#                                           cv=kfold)\n",
        "#\n",
        "# print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
        "#\n",
        "# "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Build measurement matrix.\")\n",
        "# #\n",
        "# # x0 = None\n",
        "# # Rtol = 1e-6\n",
        "# # NE_Rtol = 1e-6\n",
        "# # max_iter = 100\n",
        "# # sigmaSq = 0.0\n",
        "# # beta = 0.0\n",
        "#\n",
        "# measurement_matrix_LO = scipy.sparse.linalg.aslinearoperator(\n",
        "#     measurement_matrix)\n",
        "# input_vector = astro_noisy_vector\n",
        "#\n",
        "# # Raw RL, no imputation\n",
        "# FLAG_RAW = 0\n",
        "# if(FLAG_RAW):\n",
        "#     astro_rl_flat = richardson_lucy.matrix_reconstruction(\n",
        "#         scipy.sparse.linalg.aslinearoperator(measurement_matrix),\n",
        "#         input_vector, max_iter=30)\n",
        "#     # astro_rl = astro\n",
        "#     astro_rl = np.reshape(np.array(astro_rl_flat), astro_blur.shape)\n",
        "#\n",
        "#     fig, ax = plt.subplots(1, 3, figsize=[6.4 * 2, 4.8 * 2])\n",
        "#\n",
        "#     ax[0].imshow(astro)\n",
        "#     ax[0].title.set_text(\"Raw\")\n",
        "#\n",
        "#     ax[1].imshow(astro_noisy)\n",
        "#     ax[1].title.set_text(\"Corrupted\")\n",
        "#\n",
        "#     ax[2].imshow(astro_rl)\n",
        "#     ax[2].title.set_text(\"Recovered\")\n",
        "#\n",
        "#\n",
        "# "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# # H_df = pd.DataFrame(measurement_matrix)\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ######\n",
        "# FLAG_IMPUTE = 0\n",
        "# if(FLAG_IMPUTE):\n",
        "#     from sklearn.linear_model import BayesianRidge\n",
        "#     "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#     imp = IterativeImputer(missing_values=np.NaN,\n",
        "#                            verbose=2, estimator=BayesianRidge())\n",
        "#     imp.fit(measurement_matrix_3d_nuked)\n",
        "#     H_fixed = imp.transform(measurement_matrix_3d_nuked)\n",
        "#\n",
        "#     error = measurement_matrix - H_fixed\n",
        "#     sum_error = np.sum(np.sum(error))\n",
        "#     sum_error\n",
        "#     # plt.show()\n",
        "#     plt.savefig(\"output/H_fixed.png\")\n",
        "#     plt.imshow(H_fixed)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "resources": {
        "logo-32x32": "/kernelspecs/python3/logo-32x32.png",
        "logo-64x64": "/kernelspecs/python3/logo-64x64.png"
      },
      "language": "python",
      "display_name": "Python 3",
      "argv": [
        "/opt/conda/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}